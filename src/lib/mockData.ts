export const mockIncidents = [
  {
    id: 1,
    title: "Biased Recommendation Algorithm",
    description: "Algorithm consistently favored certain demographics in job recommendations, potentially perpetuating workplace inequalities. Investigation revealed training data imbalances and required immediate intervention to ensure fair representation across all user groups.",
    severity: "Medium",
    reported_at: "2025-03-15T10:00:00Z"
  },
  {
    id: 2,
    title: "LLM Hallucination in Critical Info",
    description: "Large Language Model provided incorrect safety procedure information in an emergency response system. This could have led to dangerous situations if the information had been followed. Immediate model retraining and validation protocols were implemented.",
    severity: "High",
    reported_at: "2025-04-01T14:30:00Z"
  },
  {
    id: 3,
    title: "Minor Data Leak via Chatbot",
    description: "Chatbot inadvertently exposed non-sensitive user metadata during conversations. While no critical information was compromised, this incident highlighted the need for stronger data filtering mechanisms in conversational AI systems.",
    severity: "Low",
    reported_at: "2025-04-10T09:15:00Z"
  },
  {
    id: 4,
    title: "AI System Resource Over Consumption",
    description: "AI model deployment caused unexpected server resource spikes, leading to temporary system slowdowns. Investigation revealed inefficient model optimization and need for better resource management protocols.",
    severity: "Medium",
    reported_at: "2025-04-15T16:45:00Z"
  },
  {
    id: 5,
    title: "Automated Decision System Failure",
    description: "Critical failure in automated decision-making system affected user access controls. System reverted to manual oversight while investigation and fixes were implemented. Highlighted need for robust fallback mechanisms.",
    severity: "High",
    reported_at: "2025-04-20T11:20:00Z"
  }
];
